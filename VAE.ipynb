{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88b2e61b",
   "metadata": {},
   "source": [
    "## Variational Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45368836",
   "metadata": {},
   "source": [
    "This notebook presents a model that can be used for data augmentation. Variational autoencoder can learn multivariate latent distribution of the input data to further reconstruct it as accurately as possible. In order to build a better organized latent space there was implemented [Cyclical Annealing Schedule](https://aclanthology.org/N19-1021.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08aa7881",
   "metadata": {},
   "source": [
    "### 0. Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edfa6f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import time\n",
    "import torch\n",
    "import wandb\n",
    "import optuna\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import stats\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "from torch import nn\n",
    "from torch.optim import lr_scheduler\n",
    "from collections import OrderedDict\n",
    "\n",
    "from src.metrics import pearson_metric\n",
    "from src.data import Dataset, load_data, build_torch_dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c348e122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4318604",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mubiquant-experiments\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd341d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda:0\"\n",
    "PROJECT = \"VAE\"\n",
    "ENTITY = \"parmezano\"\n",
    "EXPERIMENT = \"baseline + beta scheduling\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ceb74c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"Epochs\": 50,\n",
    "    \"Latent vector dim.\": 10,\n",
    "    \"Layers\": [302, 256, 128, 64, 32],\n",
    "    \"Optimizer\": \"AdamW\",\n",
    "    \"Learning rate\": 1e-3,\n",
    "    \"Weight decay\": 5e-4,\n",
    "    \"Batch size\": 25000,\n",
    "    \"Scheduler\": \"CosineAnnealingLR\",\n",
    "    \"Split data\": True,    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcc8b3ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.11 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/parmezano/VAE/runs/636f0z7e\" target=\"_blank\">baseline + beta scheduling</a></strong> to <a href=\"https://wandb.ai/parmezano/VAE\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/parmezano/VAE/runs/636f0z7e?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fd6a95fce80>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=PROJECT, entity=ENTITY, name=EXPERIMENT, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f645c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_dir = os.path.join(\"weights\", PROJECT)\n",
    "if not os.path.exists(weights_dir):\n",
    "    os.makedirs(weights_dir)\n",
    "\n",
    "model_dir = os.path.join(\"models\", PROJECT)\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2fd25b",
   "metadata": {},
   "source": [
    "### 1. Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b28b5a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading took 10.42 seconds\n"
     ]
    }
   ],
   "source": [
    "df = load_data(use_feather=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b4e12f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader, testloader = build_torch_dataloaders(df, split_data=config['Split data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e05923",
   "metadata": {},
   "source": [
    "### 2. Building a Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04ec05dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlockAE(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, activation):\n",
    "        super(BlockAE, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(input_dim, output_dim),\n",
    "            activation()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.main(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8eece0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    \n",
    "    def __init__(self, layers, dim, activation=nn.ReLU):\n",
    "        super(VAE, self).__init__()\n",
    "        self.layers = layers\n",
    "        self.dim = dim\n",
    "        self.activation = activation\n",
    "        \n",
    "        self.encoder = self.__build_encoder()\n",
    "        self.decoder = self.__build_decoder()\n",
    "\n",
    "    def __build_encoder(self):\n",
    "        layers = self.layers\n",
    "        activation = self.activation\n",
    "        encoder_layers = []\n",
    "        for idx in range(len(layers) - 1):\n",
    "            layer = BlockAE(layers[idx], layers[idx + 1], activation)\n",
    "            encoder_layers.append(layer)\n",
    "        encoder_layers.append(nn.Linear(layers[-1], self.dim * 2))\n",
    "        return torch.nn.Sequential(*encoder_layers)\n",
    "    \n",
    "    def __build_decoder(self):\n",
    "        layers = self.layers[::-1]\n",
    "        activation = self.activation\n",
    "        decoder_layers = [nn.Linear(self.dim, layers[0])]\n",
    "        for idx in range(len(layers) - 2):\n",
    "            layer = BlockAE(layers[idx], layers[idx + 1], activation)\n",
    "            decoder_layers.append(layer)\n",
    "        decoder_layers.append(nn.Linear(layers[-2], layers[-1]))\n",
    "        return torch.nn.Sequential(*decoder_layers)\n",
    "            \n",
    "    \n",
    "    def reparametrize(self, mu, sigma):\n",
    "        if self.training:\n",
    "            std = sigma.mul(0.5).exp_()\n",
    "            eps = std.new_empty(std.size()).normal_()\n",
    "            return eps.mul_(std).add_(mu)\n",
    "        return mu\n",
    "    \n",
    "    def forward(self, x):\n",
    "        bottleneck = self.encoder(x).view(-1, 2, self.dim)\n",
    "        mu, sigma = bottleneck[:, 0, :], bottleneck[:, 1, :]\n",
    "        z = self.reparametrize(mu, sigma)\n",
    "        out = self.decoder(z)\n",
    "        return out, mu, sigma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec3588ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_beta(epoch):\n",
    "    return min((epoch % 50) / 40, 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c61d639a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(x_hat, x, mu, sigma, beta=1):\n",
    "    bce = nn.L1Loss()(x_hat, x)\n",
    "    kld = 0.5 * torch.sum(sigma.exp() - sigma - 1 + mu.pow(2))\n",
    "    return bce + beta * kld"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87965160",
   "metadata": {},
   "source": [
    "### 3. Training the Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd19a866",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make():\n",
    "    model = VAE(layers=config[\"Layers\"], dim=config['Latent vector dim.'])\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=config['Learning rate'], weight_decay=config['Weight decay'])\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config['Epochs'])\n",
    "    criterion = vae_loss\n",
    "    return model, optimizer, scheduler, criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "400061b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, loader, optimizer, device='cpu'):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for i, (_x, _y) in enumerate(loader):\n",
    "        optimizer.zero_grad()\n",
    "        x = torch.cat((_x, torch.unsqueeze(_y, 1)), dim=1)\n",
    "        x = x.to(device)\n",
    "        x_hat, mu, sigma = model(x)\n",
    "        beta = compute_beta(i)\n",
    "        loss = criterion(x_hat, x, mu, sigma, beta=beta)\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return train_loss / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b4357ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, criterion, loader, device='cpu'):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, (_x, _y) in enumerate(loader):\n",
    "            x = torch.cat((_x, torch.unsqueeze(_y, 1)), dim=1)\n",
    "            x = x.to(device)\n",
    "            x_hat, mu, sigma = model(x)\n",
    "            loss = criterion(x_hat, x, mu, sigma)\n",
    "            test_loss += loss.item()\n",
    "    return test_loss / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47388eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_onnx(model):\n",
    "    dummy_input = torch.randn(302, device=\"cpu\")\n",
    "    torch.onnx.export(model.cpu(), dummy_input, f\"{model_dir}.onnx\")\n",
    "    wandb.save(f\"{model_dir}.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd37fa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_weights(test_loss, losses, epoch, model, optimizer):\n",
    "    losses.append(test_loss)\n",
    "    if test_loss <= min(losses):\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': test_loss, \n",
    "        }, os.path.join(weights_dir, f\"{epoch}.pt\"))\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c85a7e3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def pipeline(trainloader, testloader, log=False):\n",
    "    model, optimizer, scheduler, criterion = make()\n",
    "    wandb.watch(model, criterion, log=\"all\", log_freq=10)\n",
    "    losses = []\n",
    "    \n",
    "    for epoch in range(config['Epochs']):\n",
    "        train_loss = train(model, criterion, trainloader, optimizer, device=DEVICE)\n",
    "        test_loss = test(model, criterion, testloader, device=DEVICE)\n",
    "        scheduler.step()\n",
    "\n",
    "        losses = save_weights(test_loss, losses, epoch, model, optimizer)\n",
    "\n",
    "        wandb.log({\"Train loss\": train_loss, \"Test loss\": test_loss})\n",
    "        if log and epoch % 5 == 0:\n",
    "            print(f\"Epoch: {epoch+1:02d} | Train: {train_loss:.8f} | Test: {test_loss:.8f}\")\n",
    "    \n",
    "    export_onnx(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "536e5c5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Train: 0.02634314 | Test: 0.00764904\n",
      "Epoch: 06 | Train: 0.00025144 | Test: 0.00039427\n",
      "Epoch: 11 | Train: 0.00019361 | Test: 0.00026698\n",
      "Epoch: 16 | Train: 0.00017735 | Test: 0.00018584\n",
      "Epoch: 21 | Train: 0.00017690 | Test: 0.00016340\n",
      "Epoch: 26 | Train: 0.00015494 | Test: 0.00016623\n",
      "Epoch: 31 | Train: 0.00015473 | Test: 0.00017369\n",
      "Epoch: 36 | Train: 0.00015392 | Test: 0.00015936\n",
      "Epoch: 41 | Train: 0.00015407 | Test: 0.00015964\n",
      "Epoch: 46 | Train: 0.00015405 | Test: 0.00015971\n",
      "Epoch: 51 | Train: 0.00015395 | Test: 0.00015963\n",
      "Epoch: 56 | Train: 0.00015390 | Test: 0.00015946\n",
      "Epoch: 61 | Train: 0.00015375 | Test: 0.00015929\n",
      "Epoch: 66 | Train: 0.00015375 | Test: 0.00015939\n",
      "Epoch: 71 | Train: 0.00015370 | Test: 0.00015938\n",
      "Epoch: 76 | Train: 0.00015366 | Test: 0.00015913\n",
      "Epoch: 81 | Train: 0.00015358 | Test: 0.00015909\n",
      "Epoch: 86 | Train: 0.00015354 | Test: 0.00015923\n",
      "Epoch: 91 | Train: 0.00015352 | Test: 0.00015935\n",
      "Epoch: 96 | Train: 0.00015346 | Test: 0.00015898\n",
      "Epoch: 101 | Train: 0.00015338 | Test: 0.00015893\n",
      "Epoch: 106 | Train: 0.00015336 | Test: 0.00015899\n",
      "Epoch: 111 | Train: 0.00015334 | Test: 0.00015898\n",
      "Epoch: 116 | Train: 0.00015330 | Test: 0.00015912\n",
      "Epoch: 121 | Train: 0.00015331 | Test: 0.00015896\n",
      "Epoch: 126 | Train: 0.00015323 | Test: 0.00015900\n",
      "Epoch: 131 | Train: 0.00015329 | Test: 0.00015902\n",
      "Epoch: 136 | Train: 0.00015319 | Test: 0.00015885\n",
      "Epoch: 141 | Train: 0.00015328 | Test: 0.00015914\n",
      "Epoch: 146 | Train: 0.00015334 | Test: 0.00015930\n"
     ]
    }
   ],
   "source": [
    "pipeline(trainloader, testloader, log=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ef9781",
   "metadata": {},
   "source": [
    "### 4. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0b66918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE(\n",
       "  (encoder): Sequential(\n",
       "    (0): BlockAE(\n",
       "      (main): Sequential(\n",
       "        (0): Linear(in_features=302, out_features=256, bias=True)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (1): BlockAE(\n",
       "      (main): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (2): BlockAE(\n",
       "      (main): Sequential(\n",
       "        (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (3): BlockAE(\n",
       "      (main): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=32, bias=True)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (4): Linear(in_features=32, out_features=20, bias=True)\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=10, out_features=32, bias=True)\n",
       "    (1): BlockAE(\n",
       "      (main): Sequential(\n",
       "        (0): Linear(in_features=32, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (2): BlockAE(\n",
       "      (main): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=128, bias=True)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (3): BlockAE(\n",
       "      (main): Sequential(\n",
       "        (0): Linear(in_features=128, out_features=256, bias=True)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (4): Linear(in_features=256, out_features=302, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(os.path.join(weights_dir, \"49.pt\"))\n",
    "inferenced, _, _, _ = make()\n",
    "inferenced.load_state_dict(checkpoint['model_state_dict'])\n",
    "inferenced.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4cdba605",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1476, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "z = torch.randn((100, 10))\n",
    "sample = inferenced.decoder(z)\n",
    "print(torch.max(torch.abs(sample[:, -1])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
