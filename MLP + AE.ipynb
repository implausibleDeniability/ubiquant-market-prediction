{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "367fbb32",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron & Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372d0b95",
   "metadata": {},
   "source": [
    "This notebook presents a novel architecture of multilayer perceptron and autoencoder inspired by a [top-1 solution](https://www.kaggle.com/c/jane-street-market-prediction/discussion/224348) for Jane Street market competition. Both components of the system are training together on the same data. The latent-space representation produced by Autoencoder is concatenated with original set of attributes and fed into MLP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e288403f",
   "metadata": {},
   "source": [
    "### Backlog:\n",
    "1. <s> Concatenate output of AE with the input (use latent representation for a new features) </s>\n",
    "2. <s> Try Swish (SiLU) activation function </s>\n",
    "3. Add Gaussian noise layer before encoder for data augmentation\n",
    "4. Add target information to autoencoder (supervised learning) to force it to generate more relevant features, and to create a shortcut for backpropagation of gradient\n",
    "5. Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08aa7881",
   "metadata": {},
   "source": [
    "### 0. Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edfa6f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import time\n",
    "import torch\n",
    "import optuna\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import stats\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "from torch import nn\n",
    "from torch.optim import lr_scheduler\n",
    "from collections import OrderedDict\n",
    "\n",
    "from src.metrics import pearson_metric\n",
    "from src.torch_models import MLPAE\n",
    "from src.data import Dataset, load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c348e122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "371536eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda:0\"\n",
    "EPOCHS = 30\n",
    "EXPERIMENT = \"MLP+AE-baseline\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2fd25b",
   "metadata": {},
   "source": [
    "### 1. Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b28b5a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading took 7.08 seconds\n"
     ]
    }
   ],
   "source": [
    "trainloader, _ = load_data(use_feather=True, split_data=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e05923",
   "metadata": {},
   "source": [
    "### 2. Building a Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74673da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPAE(input_dim=301, mlp_depth=3, activation=nn.SiLU).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "109f3336",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, loader, optimizer, investment_id_dropout=0.01, device='cpu'):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    \n",
    "    train_loss = 0.0\n",
    "    accuracy = []\n",
    "    for i, (x, y) in enumerate(loader):\n",
    "        x[:, 0] *= (torch.rand(len(x)) > investment_id_dropout)\n",
    "        optimizer.zero_grad()\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        x_pred, y_pred = model(x)\n",
    "        \n",
    "        loss_ae = criterion(x, x_pred)\n",
    "        loss_mlp = criterion(y, y_pred.view(-1))\n",
    "        \n",
    "        loss = loss_ae + loss_mlp        \n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_ae = loss_ae.item()\n",
    "        loss_mlp = loss_mlp.item()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    losses = {\n",
    "        'ae': loss_ae / len(loader),\n",
    "        'mlp': loss_mlp / len(loader),\n",
    "        'ov': train_loss / len(loader)\n",
    "    }\n",
    "        \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4818087",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, criterion, loader, investment_id_dropout=0.01, device='cpu'):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    accuracy = []\n",
    "    with torch.no_grad():\n",
    "        for i, (x, y) in enumerate(loader):\n",
    "            x[:, 0] *= (torch.rand(len(x)) > investment_id_dropout)\n",
    "            optimizer.zero_grad()\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            x_pred, y_pred = model(x)\n",
    "\n",
    "            loss_ae = criterion(x, x_pred)\n",
    "            loss_mlp = criterion(y, y_pred.view(-1))\n",
    "\n",
    "            loss = loss_ae + loss_mlp  \n",
    "            \n",
    "            loss_ae = loss_ae.item()\n",
    "            loss_mlp = loss_mlp.item()\n",
    "            test_loss += loss.item()\n",
    "    \n",
    "    losses = {\n",
    "        'ae': loss_ae / len(loader),\n",
    "        'mlp': loss_mlp / len(loader),\n",
    "        'ov': test_loss / len(loader)\n",
    "    }\n",
    "        \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87965160",
   "metadata": {},
   "source": [
    "### 3. Training the Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4933f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_dir = os.path.join(\"weights\", EXPERIMENT)\n",
    "if not os.path.exists(experiment_dir):\n",
    "    os.makedirs(experiment_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9779f3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d481991b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 (31.6 s.) | Train AE: 0.04024 MLP: 0.00779 OV: 7924.75691 |\n",
      "Epoch: 02 (29.8 s.) | Train AE: 0.00781 MLP: 0.00760 OV: 2.56608 |\n",
      "Epoch: 03 (29.9 s.) | Train AE: 0.00783 MLP: 0.00769 OV: 2.02736 |\n",
      "Epoch: 04 (30.5 s.) | Train AE: 0.00781 MLP: 0.00700 OV: 2.01057 |\n",
      "Epoch: 05 (30.6 s.) | Train AE: 0.00789 MLP: 0.00701 OV: 2.01423 |\n",
      "Epoch: 06 (29.9 s.) | Train AE: 0.00777 MLP: 0.00695 OV: 1.99301 |\n",
      "Epoch: 07 (30.5 s.) | Train AE: 0.00774 MLP: 0.00698 OV: 2.00704 |\n",
      "Epoch: 08 (30.5 s.) | Train AE: 0.00778 MLP: 0.00692 OV: 1.97015 |\n",
      "Epoch: 09 (30.8 s.) | Train AE: 0.00776 MLP: 0.00677 OV: 1.97704 |\n",
      "Epoch: 10 (30.8 s.) | Train AE: 0.00772 MLP: 0.00701 OV: 1.97547 |\n",
      "Epoch: 11 (30.7 s.) | Train AE: 0.00774 MLP: 0.00704 OV: 1.96363 |\n",
      "Epoch: 12 (30.7 s.) | Train AE: 0.00765 MLP: 0.00675 OV: 1.96397 |\n",
      "Epoch: 13 (30.4 s.) | Train AE: 0.00763 MLP: 0.00674 OV: 1.95850 |\n",
      "Epoch: 14 (30.2 s.) | Train AE: 0.00764 MLP: 0.00688 OV: 1.95734 |\n",
      "Epoch: 15 (30.5 s.) | Train AE: 0.00767 MLP: 0.00674 OV: 1.94518 |\n",
      "Epoch: 16 (30.6 s.) | Train AE: 0.00771 MLP: 0.00678 OV: 1.94114 |\n",
      "Epoch: 17 (30.3 s.) | Train AE: 0.00875 MLP: 0.00686 OV: 1.96050 |\n",
      "Epoch: 18 (29.8 s.) | Train AE: 0.00722 MLP: 0.00685 OV: 1.91754 |\n",
      "Epoch: 19 (30.2 s.) | Train AE: 0.00711 MLP: 0.00716 OV: 1.88900 |\n",
      "Epoch: 20 (29.7 s.) | Train AE: 0.00702 MLP: 0.00673 OV: 1.87814 |\n",
      "Epoch: 21 (30.8 s.) | Train AE: 0.00689 MLP: 0.00670 OV: 1.85831 |\n",
      "Epoch: 22 (30.6 s.) | Train AE: 0.00684 MLP: 0.00698 OV: 1.83929 |\n",
      "Epoch: 23 (30.2 s.) | Train AE: 0.00675 MLP: 0.00680 OV: 1.83051 |\n",
      "Epoch: 24 (30.3 s.) | Train AE: 0.00645 MLP: 0.00676 OV: 1.81305 |\n",
      "Epoch: 25 (30.4 s.) | Train AE: 0.00644 MLP: 0.00668 OV: 1.78966 |\n",
      "Epoch: 26 (29.8 s.) | Train AE: 0.00634 MLP: 0.00687 OV: 1.79269 |\n",
      "Epoch: 27 (30.5 s.) | Train AE: 0.00631 MLP: 0.00689 OV: 1.77985 |\n",
      "Epoch: 28 (30.1 s.) | Train AE: 0.00634 MLP: 0.00713 OV: 1.76835 |\n",
      "Epoch: 29 (30.2 s.) | Train AE: 0.00608 MLP: 0.00711 OV: 1.76833 |\n",
      "Epoch: 30 (30.0 s.) | Train AE: 0.00604 MLP: 0.00713 OV: 1.76295 |\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for epoch in range(EPOCHS):\n",
    "    start_execution = time.time()\n",
    "    train_losses = train(model, criterion, trainloader, optimizer, device=DEVICE)\n",
    "    # test_losses = test(model, criterion, testloader, device=DEVICE)    \n",
    "    scheduler.step()\n",
    "    # Test AE: {test_losses['ae']:.5f} MLP: {test_losses['mlp']:.5f} OV: {test_losses['ov']:.5f} |     \n",
    "    print(f\"Epoch: {epoch+1:02d} ({time.time()-start_execution:.1f} s.) | Train AE: {train_losses['ae']:.5f} MLP: {train_losses['mlp']:.5f} OV: {train_losses['ov']:.5f} |\")\n",
    "    \n",
    "    losses.append(train_losses['ov'])\n",
    "    if train_losses['ov'] <= min(losses):\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': train_losses['ov'], \n",
    "        }, os.path.join(experiment_dir, f\"{epoch}.pt\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
